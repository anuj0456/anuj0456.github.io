---
layout: post
title: Realistic and consistent responses from LLMs by leveraging three senses
canonical_url: https://medium.com/@anuj0456/realistic-and-consistent-responses-from-llms-by-leveraging-five-senses-01e9d46f3c9c?source=rss-d2453bdab35d------2
tag:
- rags
- gpt-4
- prompt
- llm
- prompt-engineering
---

<figure><img alt="" src="https://cdn-images-1.medium.com/max/640/0*psnZslMufl6xVVd0.jpg" /></figure><blockquote>This blog is inspired from <a href="https://arxiv.org/abs/2312.16233">arXiv:2312.16233</a></blockquote><p>Language models like GPT4, BARD, BedRock have been making quite a splash lately! From improving natural language understanding to aiding in various applications like chatbots, translation, and content generation, large language models (LLMs) have been at the forefront of AI advancements. The research and development in this field have led to more nuanced and context-aware language models, enabling better communication between humans and machines. The realism and consistency of these responses can be further enhanced by providing richer information of the agent being mimicked.</p><p>But due to the significant computational resources required for training such models, prompt tuning has emerged as a crucial aspect of optimizing LLM performance. Recent research has explored various techniques to generate more realistic responses through effective prompt engineering, such as prompting a relevant pseudo dialogue or providing detailed information of the scene, relations, and attributes.The innate context limit of LLMs poses a challenge for maintaining a consistent conversational memory.</p><p>To address these challenges, a multi-pronged approach aimed at enhancing the efficacy of prompts for LLMs can be used:</p><ol><li>Information-rich Prompting — Initialize and continuously update the prompts so that it provides multi-aspect information on the character.</li><li>Within-prompt Self Memory Management — To mitigate the limitation of context length, make the language model to summarize the history log and maintain it in the prompt.</li><li>Benchmark Dataset — To overcome the scarcity of useful datasets for evaluation, augment Cornell MovieDialog Corpus2 via GPT-3.5 Turbo, a model known for its strong capabilities comparable to those of fine-tuned LLMs</li></ol><p>Results</p><p>Each component in the approach helps generate a better utterance.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/670/1*91tv-GY-vXnMs-mzzWvaSw.png" /></figure><p>In conclusion, the study highlights the effectiveness of information-rich prompting in enhancing the naturalness and realism of utterance generation when the language model emulates a fictional character.</p><p><strong>REFERENCE: </strong><a href="https://arxiv.org/abs/2312.16233"><strong>arXiv:2312.16233</strong></a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=01e9d46f3c9c" width="1" height="1" alt="">
